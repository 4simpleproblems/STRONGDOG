name: Upload Website

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      # 1. Check out the repository.
      - name: Checkout repository
        uses: actions/checkout@v3

      # 2. Configure AWS credentials for the CLI.
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1  # adjust if your bucket is in a different region

      # 3. Find and upload only files modified in the last 2 days.
      - name: Upload recently modified files
        env:
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
        run: |
          echo "Finding files modified in the last 2 days (excluding .git*, strongdog2, and strongdog3)..."
          # The find command excludes the directories you don't want, then prints any files with modification time less than 2 days.
          files=$(find . -type f \( -path "./.git*" -o -path "./strongdog2/*" -o -path "./strongdog3/*" \) -prune -o -mtime -2 -print)
          
          if [ -z "$files" ]; then
            echo "No files modified in the last 2 days."
            exit 0
          fi

          # Loop over each file and upload it individually.
          while IFS= read -r file; do
            # Remove the leading "./" from the file path.
            dest=$(echo "$file" | sed 's|^\./||')
            echo "Uploading $file to s3://$AWS_S3_BUCKET/$dest"
            aws s3 cp "$file" "s3://$AWS_S3_BUCKET/$dest" --acl public-read --follow-symlinks
          done <<< "$files"
